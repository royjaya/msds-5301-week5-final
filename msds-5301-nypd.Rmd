---
title: "Analysis of NYPD Shooting Incidents"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Assignment Description
In this assignment, we are tasked with producing a report analyzing the New York Police Department (NYPD) Shooting Incident data. As per the assignment requirement, we will generate two visualizations from the given data. Additionally, we will perform a predictive analysis on the data to check whether a shooting incident resulting in the victim's death would be counted as a murder.

## Data Description
**Source**: https://data.cityofnewyork.us/api/views/833y-fsy8/

**Description**: 	List of every shooting incident that occurred in NYC going back to 2006 through the end of the previous calendar year. This is a breakdown of every shooting incident that occurred in NYC going back to 2006 through the end of the previous calendar year. This data is manually extracted every quarter and reviewed by the Office of Management Analysis and Planning before being posted on the NYPD website. Each record represents a shooting incident in NYC and includes information about the event, the location and time of occurrence. In addition, information related to suspect and victim demographics is also included. This data can be used by the public to explore the nature of shooting/criminal activity. 


# Load libraries
Let's import the necessary libraries to run this markdown file. Some libraries share the same function name, therefore using the 'conflicted' package to resolve when there is a conflict in the functions from different libraries. 
```{r results='hide', message=FALSE, warning=FALSE}
# Turned off some flags to hide library load messages
# by using {r results='hide', message=FALSE, warning=FALSE}
# To install the packages uncomment the following two lines
# options(repos = c(CRAN = "https://cloud.r-project.org/"))
# install.packages(c("tidyverse", "lubridate", "ggplot2", "caret", "tinytex"))

library(conflicted)  
library(tidyverse)
library(lubridate)
library(ggplot2)
library(caret)
```
## Import Data
Let us import the data from the provided url. If the R version is >= 4.0, we do not need to use the parameter and value 'stringsAsFactors=FALSE'
```{r}
url <- "https://data.cityofnewyork.us/api/views/833y-fsy8/rows.csv?accessType=DOWNLOAD"
shootings <- read.csv(url, stringsAsFactors = FALSE)
# Let's look at the head of the loaded dataframe
head(shootings, n=2) # View the top 2 rows only
```

## Data Cleaning
If we have a glimpse of the data, we will see the data type for the column OCCUR_DATE is character. We convert the default OCCUR_DATE type to data type Date. 
Additionally, we see there are some NULL values. We drop the rows having NULL values. 
```{r}
glimpse(shootings)
# Statistical summary of each column in the dataframe
summary(shootings)
# Cast OCCUR_DATE as type Date
shootings$OCCUR_DATE <- as.Date(shootings$OCCUR_DATE, format="%m/%d/%Y")
# Drop rows with NULL values
shootings_clean <- shootings %>% drop_na()
head(shootings_clean, n=2) # View the top two rows only
```

## Exploratory Data Analysis

### 1. Shooting Trends Over the Years
In this section, we are going to generate a plot highlighting the trend of shooting incidents in New York City over the years. To do so we first group the incidents by year and count how many incidents are there for each year. Then we generate a line graph by plotting the year on the X-axis and associated incident counts on the Y-axis. 
```{r}
shootings_clean %>%
  mutate(Year = year(OCCUR_DATE)) %>%
  group_by(Year) %>%
  summarise(Incidents = n()) %>%
  ggplot(aes(x = Year, y = Incidents)) +
  geom_line(color = "red", linewidth = 1) +
  ggtitle("Trend of Shooting Incidents in NYC") +
  theme_minimal()
```
By visualizing the graph, we see the number of shooting incidents decreased gradually from the year 2006 to 2019. But there was a sharp increase in 2020 and 2021 which also decreased gradually after.  

### 2. Borough-wise Distribution of Shootings
In this section, we are going to generate a plot displaying the borough-wise shooting incidents that happened over the years. From the data we see there are five boroughs in NYC. In this case, we are going to use a bar graph to represent the number of incidents for each NYC borough. 

```{r}
ggplot(shootings_clean, aes(x = BORO)) +
  geom_bar(fill = "blue") +
  ggtitle("Number of Shootings by Borough") +
  theme_minimal()
```
From the plot above we can see the most number of shooting incidents happened in BROOKLYN. On the other hand, the least number of shootings happened in STATEN ISLAND. 


### 3. Predictive Modeling
Next we will perform a predictive analysis on the given NYC shooting dataset. For this analysis, let's assume we want to predict whether a shooting incident which resulted in a victim's death would be counted as murder. Therefore, the output variable for the predictive model in this case is the *STATISTICAL_MURDER_FLAG*. As far as the input variables are concerned, we can use a few independent variables or columns of the given dataset. But let's assume we want to predict whether a shooting incident is a murder by using the information about the age group (*VIC_AGE_GROUP*) of the victim and in which borough (*BOROUGH*) the shooting incident occurred. 

```{r}
# We saw our STATISTICAL_MURDER_FLAG values are "given as strings"true" and "false"
# and the data type is character or string.
# Let's convert "true" and "false" to numeric 1 and 0 respectively
shootings_clean$STATISTICAL_MURDER_FLAG <- 
  ifelse(shootings_clean$STATISTICAL_MURDER_FLAG == "true", 1, 0)

# Check the distribution of the target variable
table(shootings_clean$STATISTICAL_MURDER_FLAG)

# Ensure there are at least two unique values before partitioning
if (length(unique(shootings_clean$STATISTICAL_MURDER_FLAG)) > 1) {
  # We set a seed value to make sure the train and test set are reproducible
  set.seed(123)
  
  # We split the dataset into two parts: train and test with a ratio of 0.7 to 0.3.
  train_index <- createDataPartition(shootings_clean$STATISTICAL_MURDER_FLAG, p = 0.7, list = FALSE)
  train_data <- shootings_clean[train_index, ]
  test_data <- shootings_clean[-train_index, ]
  
  # We train a Logistic Regression Model on the train split
  model <- glm(STATISTICAL_MURDER_FLAG ~ BORO + VIC_AGE_GROUP, 
               data = train_data, 
               family = binomial)
  
  # Print a summary of the trained model
  summary(model)
  
  # We make Predictions on the test split
  predictions <- predict(model, newdata = test_data, type = "response")
  # If probability of a prediction is greater than 0.5, we consider the incident 
  # as a murder, otherwise we consider it not a murder.
  predicted_classes <- ifelse(predictions > 0.5, 1, 0)

  # Evaluate Model Accuracy
  confusionMatrix(as.factor(predicted_classes), as.factor(test_data$STATISTICAL_MURDER_FLAG))
} else {
  print("Not enough variation in the target variable for partitioning.")
}
```

### Model assesment
By looking at the confusion matrix output, we see that our Logistic Regression model trained on the train split had an accuracy of 0.8077 on the test split with a confidence interval of [0.7992, 0.816]. It suggests 80.77% of the cases were correctly identified as 'murder' from the total number of predictions the model made for 'murder'. 

## Bias Assessment

- **Data Collection Bias**: Some shootings may be underreported or misclassified.
- **Demographic Bias**: Differences in age, race, or gender classification could affect accuracy.
- **Model Bias**: Logistic regression assumes linear relationships, which may not fully capture complex patterns.


## Conclusion

This analysis provides valuable insights into shooting incidents in NYC, revealing trends over time and geographical distributions. The logistic regression model attempts to predict fatal outcomes but is limited by the available data and inherent biases. Future work could enhance accuracy by incorporating additional features such as socioeconomic data, weather conditions, or historical crime rates. Additionally, exploring more sophisticated machine learning models may provide better predictive performance. Addressing biases in data collection and model assumptions is crucial for improving the reliability of such analyses.
